{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Al-goritmus/Portfolio/blob/master/EDA_generator_univariable.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### THIS CODE WAS CREATED TO GENERATE AUTOMATIZED EDA NOTEBOOKS IN COLAB USING JSON STRUCTURE FOR CELLS AND PYTHON CONDITIONALS FOR CREATING CODE ACCORDING TO DATA TYPES IN PANDAS DATAFRAMAS"
      ],
      "metadata": {
        "id": "YtbwDArq9b77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# parameters"
      ],
      "metadata": {
        "id": "23LrMA9yphmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install and imports"
      ],
      "metadata": {
        "id": "tJjfCShTGQJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sweetviz"
      ],
      "metadata": {
        "id": "GPOJhzewQsi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyodbc\n",
        "!curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
        "!curl https://packages.microsoft.com/config/ubuntu/16.04/prod.list > /etc/apt/sources.list.d/mssql-release.list\n",
        "!sudo apt-get update\n",
        "!sudo ACCEPT_EULA=Y apt-get -q -y install msodbcsql17"
      ],
      "metadata": {
        "id": "t-wAsECLgw-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import psycopg2"
      ],
      "metadata": {
        "id": "p9u-WXH_h7bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_y3pNujylxlL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import uuid\n",
        "import matplotlib.pyplot     as plt\n",
        "import matplotlib.patches    as mpatches\n",
        "import seaborn               as sns\n",
        "import sklearn.metrics       as Metrics\n",
        "import json\n",
        "from subprocess import run\n",
        "sns.set(style=\"whitegrid\")\n",
        "import sweetviz as sv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8Ij7CP84mQsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set DB Conn\n"
      ],
      "metadata": {
        "id": "VovB-Etfg5zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# query = 'SELECT id, user_agent, ip_address, username, http_accept, path_info, attempt_time, logout_time FROM public.axes_accesslog;'"
      ],
      "metadata": {
        "id": "dfCAwWkohUdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query = open(f'{path_dir}{f}').read()\n",
        "# query = open(f'/content/drive/MyDrive/projects/Mullen/EDA automation/EDA Automation SQL/sources/los que faltan/axes_acceslog.txt').read()"
      ],
      "metadata": {
        "id": "dEYSwXHpZdTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_prods_orig = pd.read_sql_query(query, psy_conn)"
      ],
      "metadata": {
        "id": "bCRWO7azhQqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_prods_orig"
      ],
      "metadata": {
        "id": "50wGG_ffjMFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get files in folder"
      ],
      "metadata": {
        "id": "XmlYW3k-uQpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_dir = '/content/drive/MyDrive/Datos GRAM-IA.APLICADA/'\n",
        "# /content/drive/MyDrive/projects/Mullen/EDA automation/EDA Automation csv/source"
      ],
      "metadata": {
        "id": "wFEBmMC5rx7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Gvamtp7uEN8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cmd = [ 'ls', path_dir]"
      ],
      "metadata": {
        "id": "RNsDQGstsSmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = run(cmd, capture_output=True).stdout"
      ],
      "metadata": {
        "id": "AqjZvue8saP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_name = output.decode('utf-8').split('\\n')\n",
        "files_name \n"
      ],
      "metadata": {
        "id": "7AxxgADusbpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file_test = '/content/drive/MyDrive/projects/Mullen/EDA automation/EDA Automation SQL/sources/location_locationgallery.txt'"
      ],
      "metadata": {
        "id": "CvewAnlMfNR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Test\n",
        "# with open(file_test) as f:\n",
        "#     print(f.read())\n"
      ],
      "metadata": {
        "id": "bXM9RN6xd9wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query = open(file_test).read()"
      ],
      "metadata": {
        "id": "_lQeN9oTkLjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conditions_for_reading(filename):\n",
        "\n",
        "  filename = filename.lower()\n",
        "\n",
        "  return (filename.endswith('.xlsx') | \n",
        "          filename.endswith('.csv') |\n",
        "          filename.endswith('.txt') |\n",
        "          filename.endswith('.sql'))"
      ],
      "metadata": {
        "id": "u3Udc9iMq5Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_name = [file for file in files_name if conditions_for_reading(file)]\n",
        "files_name"
      ],
      "metadata": {
        "id": "jW8vAYpfqauN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions\n",
        "\n"
      ],
      "metadata": {
        "id": "FHfrOWfnusjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_str_categorical(df_serie,func_type='upper'):\n",
        "  if func_type == 'upper':\n",
        "    return df_serie.str.upper().str.strip()\n",
        "  elif func_type == 'lower':\n",
        "    return df_serie.str.lower().str.strip()\n",
        "def remove_accents_cols(df_cols):\n",
        "    return df_cols.str.replace('ñ','ni').str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "\n",
        "def remove_special_chars(df_cols):\n",
        "    return df_cols.str.replace(r'[$@&/.:-]',' ', regex=True)\n",
        "def regular_camel_case(snake_str):\n",
        "    components = snake_str.split('_')\n",
        "    return components[0] + ''.join(x.title() for x in components[1:])\n",
        "def regular_snake_case(df_cols):\n",
        "    cols = df_cols.str.replace('ñ','ni')\n",
        "    cols = cols.str.lower().str.replace('/',' ').str.replace('.',' ').str.strip()\n",
        "    cols = cols.str.replace(r'\\s+',' ',regex=True)\n",
        "    cols = cols.str.replace(' ','_')\n",
        "    return cols"
      ],
      "metadata": {
        "id": "JrHyP_K7upMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_markdown_cell(src_list):\n",
        "\n",
        "  cell = {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": src_list,\n",
        "      \"metadata\": {\n",
        "        \"id\": f\"{uuid.uuid4()}\"\n",
        "      }\n",
        "  }\n",
        "\n",
        "  return cell"
      ],
      "metadata": {
        "id": "MJhJxC4p9Vhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_code_cells(src_list):\n",
        "  \n",
        "  cell = {\"cell_type\": \"code\",\n",
        "      \"execution_count\": 'null',\n",
        "      \"metadata\": {\n",
        "        \"id\": f\"{uuid.uuid4()}\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\":src_list}\n",
        "\n",
        "  return cell"
      ],
      "metadata": {
        "id": "eEDETQzLzMOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_notebook_text(cells):\n",
        "\n",
        "  json_cells = json.dumps(cells)\n",
        "\n",
        "  str_notebook = f'''{{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {{\n",
        "    \"colab\": {{\n",
        "      \"provenance\": []\n",
        "    }},\n",
        "    \"kernelspec\": {{\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    }},\n",
        "    \"language_info\": {{\n",
        "      \"name\": \"python\"\n",
        "    }}\n",
        "  }},\n",
        "  \"cells\": {json_cells}\n",
        "}}\n",
        "'''\n",
        "\n",
        "  return str_notebook"
      ],
      "metadata": {
        "id": "j3xJtTnj7zNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_import_cells():\n",
        "\n",
        "  return [\n",
        "      {\n",
        "          \"cell_type\": \"markdown\",\n",
        "          \"source\": [\n",
        "              \"# Import libraries\"\n",
        "          ],\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          }\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "            \"!pip install sweetviz\\n\",\n",
        "          ]\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "            \"import pandas as pd\\n\",\n",
        "            \"import psycopg2\\n\",\n",
        "            \"import numpy as np\\n\",\n",
        "            \"import matplotlib.pyplot     as plt\\n\",\n",
        "            \"import matplotlib.patches    as mpatches\\n\",\n",
        "            \"import seaborn               as sns\\n\",\n",
        "            \"import sweetviz as sv\\n\",\n",
        "            \"import sklearn.metrics       as Metrics\\n\",\n",
        "            \"from google.colab import drive\\n\",\n",
        "            \"from pandas_profiling import ProfileReport\\n\",\n",
        "            \"%matplotlib inline\"\n",
        "          ]\n",
        "      }\n",
        "   ]"
      ],
      "metadata": {
        "id": "xl3MQS_loNR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_db_config(cells):\n",
        "\n",
        "  return cells + [\n",
        "      {\n",
        "          \"cell_type\": \"markdown\",\n",
        "          \"source\": [\n",
        "              \"# Set DB Conn\"\n",
        "          ],\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          }\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "            \"DB_params = {\\n\",\n",
        "            f\"\\t'host':'{DB_params['host']}',\\n\",\n",
        "            f\"\\t'port':{DB_params['port']},\\n\",\n",
        "            f\"\\t'database':'{DB_params['database']}',\\n\",\n",
        "            f\"\\t'user':'{DB_params['user']}',\\n\",\n",
        "            f\"\\t'password':'{DB_params['password']}',\\n\",\n",
        "            \"}\"\n",
        "          ]\n",
        "      }\n",
        "   ]"
      ],
      "metadata": {
        "id": "cWeZ2EaYl3f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_read_from_db(cells, query):\n",
        "  return cells + [\n",
        "      {\n",
        "          \"cell_type\": \"markdown\",\n",
        "          \"source\": [\n",
        "              \"# Read data from DB\"\n",
        "          ],\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          }\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "            \"psy_conn = psycopg2.connect(**DB_params)\"\n",
        "          ]\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "            f\"query = '{query}'\"\n",
        "          ]\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "            \"df = pd.read_sql_query(query, psy_conn)\"\n",
        "          ]\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "            f\"df\"\n",
        "          ]\n",
        "      }\n",
        "   ]"
      ],
      "metadata": {
        "id": "z_0rC9C7tEP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_readfile_cells(cells, path_dirname,filename,sheet):\n",
        "  \n",
        "  isExcel = filename.endswith('xlsx')\n",
        "\n",
        "  return cells + [\n",
        "      {\n",
        "          \"cell_type\": \"markdown\",\n",
        "          \"source\": [\n",
        "              \"# Read file\"\n",
        "          ],\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          }\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "            \"drive.mount('/content/drive')\\n\"\n",
        "          ]\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "            f\"path_dir = '{path_dirname}'\\n\",\n",
        "            f\"filename = '{filename}'\\n\",\n",
        "            f\"sheet = '{sheet}'\\n\" if isExcel else ''\n",
        "          ]\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "            \"df = pd.read_excel(f'{path_dir}{filename}', sheet_name=sheet, header=0)\" if isExcel else \"df = pd.read_csv(f'{path_dir}{filename}')\"\n",
        "          ]\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "            f\"df\"\n",
        "          ]\n",
        "      }\n",
        "   ]"
      ],
      "metadata": {
        "id": "D0h9uzVeyXbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_normalize_cols_cells(cells):\n",
        "\n",
        "  return cells + [\n",
        "      {\n",
        "          \"cell_type\": \"markdown\",\n",
        "          \"source\": [\n",
        "              \"# Normalize_cols\"\n",
        "          ],\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          }\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "          \"def remove_accents_cols(df_cols):\\n\"\n",
        "          \"    return df_cols.str.replace('ñ','ni').str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\\n\",\n",
        "          \"def remove_special_chars(df_cols):\\n\"\n",
        "          \"    return df_cols.str.replace(r'[$@&/.:-]',' ', regex=True)\\n\",\n",
        "          \"def regular_camel_case(snake_str):\\n\"\n",
        "          \"    components = snake_str.split('_')\\n\"\n",
        "          \"    return components[0] + ''.join(x.title() for x in components[1:])\\n\",\n",
        "          \"def regular_snake_case(df_cols):\\n\"\n",
        "          \"    cols = df_cols.str.replace('ñ','ni')\\n\"\n",
        "          \"    cols = cols.str.lower().str.replace('/',' ').str.replace('.',' ').str.strip()\\n\"\n",
        "          \"    cols = cols.str.replace(r'\\s+',' ',regex=True)\\n\"\n",
        "          \"    cols = cols.str.replace(' ','_')\\n\"\n",
        "          \"    return cols\"\n",
        "          ]\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "              \"df.columns = remove_accents_cols(df.columns)\\n\",\n",
        "              \"df.columns = remove_special_chars(df.columns)\\n\",\n",
        "              \"df.columns = regular_snake_case(df.columns)\"\n",
        "          ]\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "            f\"df\"\n",
        "          ]\n",
        "      }]"
      ],
      "metadata": {
        "id": "QObKJn6LKbu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_general_stats_cells(cells):\n",
        "  return cells + [\n",
        "      {\n",
        "          \"cell_type\": \"markdown\",\n",
        "          \"source\": [\n",
        "              \"# General stats cells\"\n",
        "          ],\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          }\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\"df.describe()\",\n",
        "          ]\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\"df.dtypes\\n\"\n",
        "          ]\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "            \"df.info()\"\n",
        "          ]\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": [\n",
        "            \"print('recuento de columnas por tipo: ', df.dtypes.value_counts())\\n\",\n",
        "            \"print('sumatoria de valores nulos en el dataframe: ', df.isna().sum())\",\n",
        "          ]\n",
        "      }\n",
        "      ]"
      ],
      "metadata": {
        "id": "_5lfP2PS2_gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_profiling_cells(cells):\n",
        "  return cells + [\n",
        "      {\n",
        "          \"cell_type\": \"markdown\",\n",
        "          \"source\": [\n",
        "              \"# Profiling_library_install_cells\"\n",
        "          ],\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          }\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": ['profile = ProfileReport(df)\\n'\n",
        "              'df.profile_report()\\n',\n",
        "            'profile.to_file(\"reporte_html_para_clientes.html\")'\n",
        "          ]\n",
        "      }]"
      ],
      "metadata": {
        "id": "YalHq4HR5IOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_cell(cells,new_cells):\n",
        "  return cells + new_cells"
      ],
      "metadata": {
        "id": "vMfT4IbQxueS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_sweetviz_cells(cells_p, path_dir,f,sheet):\n",
        "  return cells_p + [\n",
        "      {\n",
        "          \"cell_type\": \"markdown\",\n",
        "          \"source\": [\n",
        "              \"# Sweetviz report\"\n",
        "          ],\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          }\n",
        "      },\n",
        "      {\n",
        "          \"cell_type\": \"code\",\n",
        "          \"execution_count\": 'null',\n",
        "          \"metadata\": {\n",
        "            \"id\": f\"{uuid.uuid4()}\"\n",
        "          },\n",
        "          \"outputs\": [],\n",
        "          \"source\": ['sweet_report = sv.analyze(df)\\n',\n",
        "                     f\"sweet_report.show_html(f'{{path_dir}}sw_report_{f}_{sheet}.html')\"\n",
        "          ]\n",
        "      }]\n",
        "\n",
        "  pass"
      ],
      "metadata": {
        "id": "s9veRcPz6R24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_notebook_file(filename,str_content):\n",
        "  with open(f'{path_dir}EDA_{filename}.ipynb', 'w') as writefile:\n",
        "    writefile.write(str_content)"
      ],
      "metadata": {
        "id": "li_abcQkaHj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def object_cells(serie):\n",
        "  n_rows = serie.size\n",
        "  col = serie.name\n",
        "  # print('my col',serie.name)\n",
        "  \n",
        "  isna_val = serie.isna().sum()\n",
        "  non_null_values = n_rows - isna_val\n",
        "\n",
        "  null_nums = pd.to_numeric(serie, errors='coerce').isna().sum()\n",
        "  converted_num = n_rows - null_nums\n",
        "\n",
        "  null_dates = pd.to_datetime(serie, errors='coerce').isna().sum()\n",
        "  converted_date = n_rows - null_dates\n",
        "\n",
        "  contains_str = serie.str.contains('^[a-zA-Z]').any()\n",
        "\n",
        "  cells_c = []\n",
        "\n",
        "  # Validador de tipos de columna\n",
        "  if (converted_num == 0 and converted_date == 0) or (contains_str == True):\n",
        "    \n",
        "    cells_c = add_cell(cells_c,[create_code_cells([\n",
        "        f\"df['{col}'] = df['{col}'].astype(str)\\n\",\n",
        "        f\"df['{col}'] = df['{col}'].str.replace('.0','')\\n\",\n",
        "        f\"df['{col}'].unique()\"])\n",
        "      ])\n",
        "\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"df['{col}'].value_counts()\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"plt.figure(figsize=(10,5))\\n\",f\"df['{col}'].value_counts()[:15].plot(kind='pie')\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"plt.figure(figsize=(30,5))\\n\",f\"df['{col}'].value_counts()[:15].plot(kind='barh')\"])])\n",
        "\n",
        "  # TODO: Rewrite next code                              \n",
        "  elif converted_date > converted_num :\n",
        "\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"df['{col}'] = pd.to_datetime(df[f'{col}'], errors='coerce')\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('la columna {col} es: ',df[f'{col}'].dtype)\"])])\n",
        "\n",
        "  elif converted_num >= converted_date:\n",
        "\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"df['{col}'] = pd.to_numeric(df[f'{col}'], errors='coerce')\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('la media es: ',df['{col}'].mean())\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('la moda es: ',df['{col}'].mode())\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('la mediana es: ',df['{col}'].median())\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('el valor mínimo de {col} es: : ',df['{col}'].min())\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('el valor máximo de {col} es: : ',df['{col}'].max())\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('el rango de {col} es: : ',df['{col}'].max() - df['{col}'].min())\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('la desviación éstandar de {col} es: : ',df['{col}'].std())\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"sns.histplot(data = df,x = '{col}')\\n\", f\"plt.axvline(x=df.{col}.mean(),color='red',linestyle='dashed',linewidth=2)\"])])\n",
        "\n",
        "\n",
        "\n",
        "  return cells_c\n"
      ],
      "metadata": {
        "id": "NO_LtGbo_IIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def int_cells(serie):\n",
        "  col = serie.name\n",
        "  n_rows = serie.size\n",
        "  unique_counts = df[col].unique().sum()\n",
        "\n",
        "  cells_c = []\n",
        "\n",
        "  if unique_counts < 0.2 * n_rows:\n",
        "\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"df['{col}'] = df['{col}'].astype(str)\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"df['{col}'] = df['{col}'].str.replace('.0','')\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"df['{col}'].unique()\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"df['{col}'].value_counts()\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"plt.figure(figsize=(10,5))\\n\",\n",
        "                                    f\"df['{col}'].value_counts()[:15].plot(kind='pie')\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"plt.figure(figsize=(30,15))\\n\",\n",
        "                                    f\"df['{col}'].value_counts()[:15].plot(kind='barh')\"])])\n",
        "  else:\n",
        "\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"df['{col}'] = pd.to_numeric(df[f'{col}'], errors='coerce')\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('la media es: ',df['{col}'].mean())\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('la moda es: ',df['{col}'].mode())\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('la mediana es: ',df['{col}'].median())\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('el valor mínimo de {col} es: : ',df['{col}'].min())\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('el valor máximo de {col} es: : ',df['{col}'].max())\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('el rango de {col} es: : ',df['{col}'].max() - df['{col}'].min())\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"print('la desviación éstandar de {col} es: : ',df['{col}'].std())\"])])\n",
        "    cells_c = add_cell(cells_c,[create_code_cells([f\"sns.histplot(data = df,x = '{col}')\\n\",f\"plt.axvline(x=df['{col}'].mean(),color='red',linestyle='dashed',linewidth=2)\"])])\n",
        "\n",
        "  return cells_c"
      ],
      "metadata": {
        "id": "GNuyr7-aQXGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def float_cells(serie):\n",
        "  col = serie.name\n",
        "  cells_c = []\n",
        "\n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"df['{col}'] = pd.to_numeric(df[f'{col}'], errors='coerce')\"])])\n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"print('la media es: ',df['{col}'].mean())\"])])\n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"print('la moda es: ',df['{col}'].mode())\"])])\n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"print('la mediana es: ',df['{col}'].median())\"])])\n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"print('el valor mínimo de {col} es: : ',df['{col}'].min())\"])])\n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"print('el valor máximo de {col} es: : ',df['{col}'].max())\"])])\n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"print('el rango de {col} es: : ',df['{col}'].max() - df['{col}'].min())\"])])\n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"print('la desviación éstandar de {col} es: : ',df['{col}'].std())\"])])\n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"sns.histplot(data = df,x = '{col}')\\n\",f\"plt.axvline(x=df['{col}'].mean(),color='red',linestyle='dashed',linewidth=2)\"])])\n",
        "  return cells_c"
      ],
      "metadata": {
        "id": "-lljPux7QdJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def datetime_cells(serie):\n",
        "  col = serie.name\n",
        "  cells_c = []\n",
        "  \n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"df['{col}'] = pd.to_datetime(df[f'{col}'], errors='coerce')\"])])\n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"print('la columna {col} es: ',df[f'{col}'].dtype)\"])])\n",
        "  return cells_c"
      ],
      "metadata": {
        "id": "VZrpnGmGQgyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bool_cells(serie):\n",
        "  col = serie.name\n",
        "  cells_c = []\n",
        "\n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"df['{col}'].unique()\"])])\n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"df['{col}'].value_counts()\"])])\n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"plt.figure(figsize=(10,5))\\n\",\n",
        "                                    f\"df['{col}'].value_counts()[:15].plot(kind='pie')\"])])\n",
        "  cells_c = add_cell(cells_c,[create_code_cells([f\"plt.figure(figsize=(30,15))\\n\",\n",
        "                                  f\"df['{col}'].value_counts()[:15].plot(kind='barh')\"])])\n",
        "  return cells_c"
      ],
      "metadata": {
        "id": "GyjaOOVxQhQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actions_for_dtype = {\n",
        "    'object': object_cells,\n",
        "    'int64': int_cells,\n",
        "    'float64': float_cells,\n",
        "    'datetime64[ns]': datetime_cells,\n",
        "    'bool': bool_cells\n",
        "}"
      ],
      "metadata": {
        "id": "vAEsNFlZ402G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_columns_analysis_cells(cells_p,df_p):\n",
        "  # add lines to cell analysis\n",
        "  # new_cells = add code\n",
        "  # cells.append(create_markdown_cell([f\"## {j}\"]))\n",
        "  # cells.append(create_code_cells([f\"df['{j}'].dtype\"]))\n",
        "  new_cells = add_cell(cells_p,[create_markdown_cell([f\"# General Analyst by columns\"])])\n",
        "  for col in df_p.columns:\n",
        "    col_type = df_p[col].dtype\n",
        "    new_cells = add_cell(new_cells,[\n",
        "        create_markdown_cell([f\"## {col}\\n\",\n",
        "                              f\"type: {df_p[col].dtype}\"]),\n",
        "        # create_code_cells([f\"df_p['{col}'].dtype\"]),\n",
        "                                    ])\n",
        "    # new_cells = new_cells + actions_for_dtype[col_type] \n",
        "    # print(col,col_type)\n",
        "    new_cells = add_cell(new_cells,actions_for_dtype[f'{col_type}'](df_p[col])) \n",
        "\n",
        "  return new_cells"
      ],
      "metadata": {
        "id": "n_8uqmxj5M8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add_cell(cells,actions_for_dtype[f\"{df['nombre1'].dtype}\"](df['nombre1'],'nombre1'))"
      ],
      "metadata": {
        "id": "bZ3aIqn_NUfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create reports\n",
        "Ahora pongo algun texto aqui"
      ],
      "metadata": {
        "id": "Hz7IorKwirNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_report_file = ''\n",
        "text_report_sheet = ''\n",
        "counter_structured_files = 0\n",
        "for f in files_name:\n",
        "  if '.xlsx' in f:\n",
        "    try:\n",
        "      xls = pd.ExcelFile(f'{path_dir}{f}')\n",
        "      counter_structured_files = counter_structured_files + 1\n",
        "      sheets = xls.sheet_names\n",
        "      cols_total = 0\n",
        "      vol_total = 0\n",
        "\n",
        "      for sheet in sheets:\n",
        "        print(f'reading {f} in sheet: {sheet}')\n",
        "        \n",
        "        # Read df from file by sheets\n",
        "        df = pd.read_excel(f'{path_dir}{f}', sheet_name=sheet, header=0)\n",
        "        #new_header = df.iloc[0] #grab the first row for the header \n",
        "        #df = df[1:] #take the data less the header row \n",
        "        #df.columns = new_header #set the header row as the df header\n",
        "\n",
        "        # Format columns\n",
        "        df.columns = remove_accents_cols(df.columns)\n",
        "        df.columns = remove_special_chars(df.columns)\n",
        "        df.columns = regular_snake_case(df.columns)\n",
        "\n",
        "        cols = len(df.columns)\n",
        "        cols_total = cols_total + cols\n",
        "        vol = df.shape[0]*df.shape[1]\n",
        "        vol_total = vol_total + vol\n",
        "        \n",
        "        text_report_sheet = text_report_sheet+f'{f}\\t{sheet}\\t{cols}\\t{df.shape}\\t{vol}\\n'\n",
        "\n",
        "        # Create cells for generated Notebook\n",
        "        cells = add_import_cells()\n",
        "        cells = add_readfile_cells(cells, path_dir,f,sheet)\n",
        "        cells = add_normalize_cols_cells(cells)\n",
        "        cells = add_general_stats_cells(cells)\n",
        "        cells = add_columns_analysis_cells(cells,df)\n",
        "        # cells = add_profiling_cells(cells)\n",
        "        cells = add_sweetviz_cells(cells, path_dir,f,sheet)\n",
        "\n",
        "        # Create Notebook .ipynb file\n",
        "        format_file_string = create_notebook_text(cells)\n",
        "        create_notebook_file(f\"{f}_{sheet}\",format_file_string)\n",
        "\n",
        "        # sweet_report = sv.analyze(df)\n",
        "        # sweet_report.show_html(f'{path_dir}{f}_sweetviz_report.html')\n",
        "\n",
        "\n",
        "        text_report_file = text_report_file+f'{f}\\t{len(sheets)}\\t{sheets}\\t{cols_total}\\t{vol_total}\\n'\n",
        "    except Exception as e:\n",
        "      print('Error reading',f)\n",
        "      print(f'Error: {e}')\n",
        "  elif '.csv' in f:\n",
        "    try:\n",
        "      df = pd.read_csv(f'{path_dir}{f}', sep=',')\n",
        "      counter_structured_files = counter_structured_files + 1\n",
        "      cols = len(df.columns)\n",
        "      cols_total = cols_total + cols\n",
        "      vol = df.shape[0]*df.shape[1]\n",
        "      vol_total = vol_total + vol\n",
        "\n",
        "      sheet = ''\n",
        "\n",
        "      # Format columns\n",
        "      df.columns = remove_accents_cols(df.columns)\n",
        "      df.columns = remove_special_chars(df.columns)\n",
        "      df.columns = regular_snake_case(df.columns)\n",
        "\n",
        "\n",
        "      text_report_sheet = text_report_sheet+f'{f}\\t1\\t{cols}\\t{df.shape}\\t{vol}\\n'\n",
        "      text_report_file = text_report_file+f'{f}\\t1\\t\\t{cols_total}\\t{vol_total}\\n'\n",
        "\n",
        "      # Create cells for generated Notebook\n",
        "      cells = add_import_cells()\n",
        "      cells = add_readfile_cells(cells, path_dir,f,sheet)\n",
        "      cells = add_normalize_cols_cells(cells)\n",
        "      cells = add_general_stats_cells(cells)\n",
        "      cells = add_columns_analysis_cells(cells,df)\n",
        "      # cells = add_profiling_cells(cells)\n",
        "      cells = add_sweetviz_cells(cells, path_dir,f,sheet)\n",
        "\n",
        "      print(f,df.columns)\n",
        "      print(cells)\n",
        "      # Create Notebook .ipynb file\n",
        "      format_file_string = create_notebook_text(cells)\n",
        "      create_notebook_file(f\"{f}_{sheet}\",format_file_string)\n",
        "    except:\n",
        "      print('error reading csv',f)\n",
        "\n",
        "  elif '.txt' in f:\n",
        "    try:\n",
        "      query = open(f'{path_dir}{f}').read()\n",
        "      df = pd.read_sql_query(query, psy_conn)\n",
        "\n",
        "      cols_total = 0\n",
        "      vol_total = 0\n",
        "      \n",
        "      # print(df.columns)\n",
        "      # Format columns\n",
        "      df.columns = remove_accents_cols(df.columns)\n",
        "      df.columns = remove_special_chars(df.columns)\n",
        "      df.columns = regular_snake_case(df.columns)\n",
        "\n",
        "      cols = len(df.columns)\n",
        "      cols_total = cols_total + cols\n",
        "      vol = df.shape[0]*df.shape[1]\n",
        "      vol_total = vol_total + vol\n",
        "      \n",
        "      # text_report_sheet = text_report_sheet+f'{f}\\t{sheet}\\t{cols}\\t{df.shape}\\t{vol}\\n'\n",
        "\n",
        "      # Create cells for generated Notebook\n",
        "      cells = add_import_cells()\n",
        "      cells = add_db_config(cells)\n",
        "      cells = add_read_from_db(cells, query)\n",
        "      cells = add_normalize_cols_cells(cells)\n",
        "      cells = add_general_stats_cells(cells)\n",
        "      cells = add_columns_analysis_cells(cells,df)\n",
        "      # cells = add_profiling_cells(cells)\n",
        "      # cells = add_sweetviz_cells(cells, path_dir,f,sheet)\n",
        "\n",
        "      # Create Notebook .ipynb file\n",
        "      format_file_string = create_notebook_text(cells)\n",
        "      create_notebook_file(f\"{f}\",format_file_string)\n",
        "\n",
        "      sweet_report = sv.analyze(df)\n",
        "      sweet_report.show_html(f'{path_dir}{f}_sweetviz_report.html')\n",
        "\n",
        "\n",
        "      # text_report_file = text_report_file+f'{f}\\t{len(sheets)}\\t{sheets}\\t{cols_total}\\t{vol_total}\\n'\n",
        "\n",
        "    except Exception as e:\n",
        "      print('error reading csv',f)\n",
        "      print(f'error: {e}')\n",
        "    # print(f'{df.shape}\\t{sheet}')\n",
        "  # print(f,len(sheets),cols_total,sheets)\n",
        "# text_report_file = text_report_file+f'{len(files_name)} files xlsx or csv'"
      ],
      "metadata": {
        "id": "fNeqEZOfuyUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#with open(f'{path_dir}text_report_file.txt', 'w') as writefile:\n",
        "#    writefile.write(text_report_file)"
      ],
      "metadata": {
        "id": "iXgvsMDv4w8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'{path_dir}text_report_sheet.txt', 'w') as writefile:\n",
        "    writefile.write(text_report_sheet)"
      ],
      "metadata": {
        "id": "h1YTweeCF_Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXPERIMENTS WHILE DEVELOPING"
      ],
      "metadata": {
        "id": "paU6B7whjFuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_excel(f'/content/drive/MyDrive/EDA automation/example_sources/Reporte_2022-7.xlsx', sheet_name='Sheet1')"
      ],
      "metadata": {
        "id": "jgmxb7oR9CfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "6FAnh_mN9KkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cells = [{\"cell_type\": \"code\",\n",
        "#       \"execution_count\": 'null',\n",
        "#       \"metadata\": {\n",
        "#         \"id\": \"_y3pNujylxlL\"\n",
        "#       },\n",
        "#       \"outputs\": [],\n",
        "#       \"source\": [\n",
        "#         \"import pandas as pd\\n\",\n",
        "#         \"import numpy as np\\n\",\n",
        "#         \"import matplotlib.pyplot     as plt\\n\",\n",
        "#         \"import matplotlib.patches    as mpatches\\n\",\n",
        "#         \"import seaborn               as sns\\n\",\n",
        "#         \"import sklearn.metrics       as Metrics\\n\",\n",
        "#         \"from subprocess import run\\n\"\n",
        "#       ]}]"
      ],
      "metadata": {
        "id": "rsUgXXpCWf4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cells.append({\n",
        "#       \"cell_type\": \"markdown\",\n",
        "#       \"source\": [\n",
        "#         \"# section 1\"\n",
        "#       ],\n",
        "#       \"metadata\": {\n",
        "#         \"id\": \"oWrMNW1aX9VU\"\n",
        "#       }\n",
        "#     })"
      ],
      "metadata": {
        "id": "yDXNpm5HXh7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# json_string = json.dumps(cells)"
      ],
      "metadata": {
        "id": "CxCKRR57WdIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# json_string"
      ],
      "metadata": {
        "id": "F_GcVVy_XXVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-bZaE2Ln6w80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T9BKk2r1Y6cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cells_for_type():\n",
        "  return 'cells for object'\n"
      ],
      "metadata": {
        "id": "J_8si6CkCWli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actions = {\n",
        "    'int': lambda x: print(x),\n",
        "    'category': lambda d_type: print(d_type),\n",
        "    'object': cells_for_type\n",
        "}"
      ],
      "metadata": {
        "id": "MeMevb-NBrZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actions['object']()"
      ],
      "metadata": {
        "id": "4lmL58cXB0yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ser = pd.Series([3,5,3,5])"
      ],
      "metadata": {
        "id": "TDzepx-CB3cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ser.size"
      ],
      "metadata": {
        "id": "xAtykdMAI-Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IUTXaf6KJAyg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}